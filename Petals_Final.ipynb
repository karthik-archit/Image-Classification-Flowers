{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4536,"status":"ok","timestamp":1665138283149,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"nCrGz0bwjdtc","outputId":"682ed31e-a5b3-4376-9c89-2b2fb716d7b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"]}],"source":["!pip install kaggle\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5xgzffglvze"},"outputs":[],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Petals\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46346,"status":"ok","timestamp":1663521624547,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"DTukQYUWmN_Z","outputId":"c97b0c96-1a12-40af-8a6d-ba7c56badc69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading tpu-getting-started.zip to /content\n","100% 4.77G/4.79G [00:45<00:00, 134MB/s]\n","100% 4.79G/4.79G [00:45<00:00, 113MB/s]\n"]}],"source":["!kaggle competitions download -c tpu-getting-started"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tt_atXf2qIKM"},"outputs":[],"source":["!unzip \"/content/drive/MyDrive/tpu-getting-started.zip\" -d \"/content/drive/MyDrive/Petals/\""]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2233,"status":"ok","timestamp":1667063058972,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"VMGunCO84wq5"},"outputs":[],"source":["from tensorflow.keras.layers import Dense,LSTM,Embedding,Dropout,Bidirectional,GRU,Flatten,BatchNormalization,GlobalAveragePooling2D\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n","from tensorflow.keras import preprocessing\n","from tensorflow.keras import optimizers\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import regularizers\n","import pandas as pd \n","import numpy as np\n","from sklearn.feature_extraction import FeatureHasher\n","from tensorflow.keras.metrics import MeanSquaredLogarithmicError\n","from tensorflow.keras.applications import InceptionV3,ResNet50V2,EfficientNetB2\n","import os\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":491,"status":"ok","timestamp":1667063506169,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"vI9SN_ZkRxdD"},"outputs":[],"source":["GCS_DS_PATH = '/content/drive/MyDrive/Colab Notebooks/Petals'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063508958,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"ZJR1GbwiRiOQ"},"outputs":[],"source":["IMAGE_SIZE = [224, 224]\n","EPOCHS = 100\n","BATCH_SIZE = 64\n","NUM_TRAINING_IMAGES = 12753\n","NUM_TEST_IMAGES = 7382\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","AUTOTUNE = tf.data.AUTOTUNE"]},{"cell_type":"markdown","metadata":{"id":"Hr1zSYYwQjpy"},"source":["Data augumentation is used , as there a lot of classes for classification and with a small dataset , data agumentation can help produce randomly transformed images of acutal images and are classified to the same label. This helps the model to extract key features more precessively , even when some parts of the images are missing or have different contrast or translated along both the axis or zoomed in etc. It essesntially helps us increase our training dataset. Keras preprocessing layers are used and they are applied to the datasets during the time of training.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2536,"status":"ok","timestamp":1667063519405,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"AWGqybERhyQZ"},"outputs":[],"source":["data_augmentation = tf.keras.Sequential([\n","  layers.RandomFlip(\"horizontal_and_vertical\"),\n","  layers.RandomRotation(0.2),\n","  layers.RandomTranslation(0.2,0.2,fill_mode=\"reflect\"),\n","  # layers.RandomContrast(0.3),\n","  layers.RandomZoom(0.1)\n","])"]},{"cell_type":"markdown","metadata":{"id":"WwVV_L-ISoxk"},"source":["Random erasing function is used to randomly erase a certain part of the image , creating a black mask. The function first gets the dimensions of the image and using sh and sl which correspond to max and min ratio of total image area and computes the upper and lower bound of possible erasing area. Then the maximum possible height and width of the erasing area is found. Then the position of the erasing is area is randomly found and finally it is applied onto the image. "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063521549,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"uqo71D7sP4FA"},"outputs":[],"source":["def random_erasing(img, sl=0.1, sh=0.2, rl=0.4, p=0.3):\n","    h = tf.shape(img)[0]\n","    w = tf.shape(img)[1]\n","    c = tf.shape(img)[2]\n","    origin_area = tf.cast(h*w, tf.float32)\n","\n","    e_size_l = tf.cast(tf.round(tf.sqrt(origin_area * sl * rl)), tf.int32)\n","    e_size_h = tf.cast(tf.round(tf.sqrt(origin_area * sh / rl)), tf.int32)\n","\n","    e_height_h = tf.minimum(e_size_h, h)\n","    e_width_h = tf.minimum(e_size_h, w)\n","\n","    erase_height = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_height_h, dtype=tf.int32)\n","    erase_width = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_width_h, dtype=tf.int32)\n","\n","    erase_area = tf.zeros(shape=[erase_height, erase_width, c])\n","    erase_area = tf.cast(erase_area, tf.uint8)\n","\n","    pad_h = h - erase_height\n","    pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n","    pad_bottom = pad_h - pad_top\n","\n","    pad_w = w - erase_width\n","    pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n","    pad_right = pad_w - pad_left\n","\n","    erase_mask = tf.pad([erase_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n","    erase_mask = tf.squeeze(erase_mask, axis=0)\n","    erased_img = tf.multiply(tf.cast(img,tf.float32), tf.cast(erase_mask, tf.float32))\n","\n","    return tf.cond(tf.random.uniform([], 0, 1) > p, lambda: tf.cast(img, img.dtype), lambda:  tf.cast(erased_img, img.dtype))"]},{"cell_type":"markdown","metadata":{"id":"RX-6KKtRdebE"},"source":["This function is used to decode the image from the tensor and convert the pixel values between 0,1."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063524469,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"im_yNeG9dct6"},"outputs":[],"source":["def decode_image(image_data):\n","    image = tf.image.decode_jpeg(image_data, channels=3)\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n","    return image\n"]},{"cell_type":"markdown","metadata":{"id":"-EoUYAW8dqI2"},"source":["This functions maps each of the image obtained from the tfrecord , which contains the image and label as tensors to their respective types and decode image is called to decode the image."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063527481,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"SXztzE1tdqlf"},"outputs":[],"source":["def read_labeled_tfrecord(example):\n","    LABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n","    }\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    label = tf.cast(example['class'], tf.int32)\n","    return image, label # returns a dataset of (image, label) pairs"]},{"cell_type":"markdown","metadata":{"id":"1BZjBwa3e4Td"},"source":["This function is used to load the datasets from the tfrecords files , based on labeled value ie , whether it is train or test data the appropriate function for mapping the records is called ."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063531488,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"IfLi_5V6e4pQ"},"outputs":[],"source":["def load_dataset(filenames, labeled=True, ordered=False):\n","\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False\n","\n","    dataset = tf.data.TFRecordDataset(filenames) \n","    dataset = dataset.with_options(ignore_order) \n","    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord,num_parallel_calls = AUTOTUNE)\n","\n","\n","    return dataset"]},{"cell_type":"markdown","metadata":{"id":"UANPnwSlfWRG"},"source":["The following functions load the files from the local directory and get the tfrecords mapped to the corresponding types using the above functions. Augumentation and erasing functions are applied to the function using the map function of tf datasets. Repeat is used as the dataset has to fetch the values for every epoch , and shuffle enables shuffling the data in the buffer. Prefetch is called so when training of one epoch is going on simultaneously the elements for next epoch or fetched to the buffer , the buffer size is dynamically chosen using Autotune depending upon the availablility of resources."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063533703,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"--OqvDFTfWxG"},"outputs":[],"source":["def get_training_dataset():\n","    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-224x224/train/*.tfrec'), labeled=True)\n","    dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), \n","                num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.map(lambda x, y: (random_erasing(x), y), \n","                num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","  \n","    return dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","def get_validation_dataset():\n","    dataset = load_dataset(tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords-jpeg-224x224/val/*.tfrec'), labeled=True, ordered=False)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    return dataset\n","    "]},{"cell_type":"markdown","metadata":{"id":"foL3pObziUnh"},"source":["Getting our training and validation Datasets."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1857,"status":"ok","timestamp":1667063539803,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"wPNCl3SuiVCb"},"outputs":[],"source":["training_dataset = get_training_dataset()\n","validation_dataset = get_validation_dataset()"]},{"cell_type":"markdown","metadata":{"id":"ZhdljhfClRM3"},"source":["Inception V3 is used with the weights of imagenet , include top is set to false because we will provide our own head to our model as the classification is different when comapred to imagenet. The first 249 layers are not trained. An another way would be training our head by freezing the whole inception model and then fine tuning it  by unfreezing a few layers . It can also be trained using a custom training loop if required. But for simplicity im training few of the higher layers of the inception model as a part of the main train run."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3895,"status":"ok","timestamp":1667063545839,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"hXqzMfApSVtX","outputId":"80865ab7-69e6-444e-f0a5-0d7116f3d48b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 2s 0us/step\n"]}],"source":["inception = InceptionV3(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n","\n","for layer in inception.layers[:249]:\n","   layer.trainable = False\n","for layer in inception.layers[249:]:\n","   layer.trainable = True"]},{"cell_type":"markdown","metadata":{"id":"foXVNZ5imtLC"},"source":["Our Model is created , again for simplicity purpose im using the sequntial model and buling feed forward network as our head. Loss is sparse_categorical_crossentropy as we are doing multi-label classification. "]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ae5UpU6rS5rf","executionInfo":{"status":"ok","timestamp":1667063548750,"user_tz":-330,"elapsed":1412,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"}}},"outputs":[],"source":["model = Sequential()\n","model.add(inception)\n","model.add(layers.Flatten())\n","model.add(Dense(512,activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(Dense(256,activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(Dense(104,activation='softmax'))\n","model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n","    loss = 'sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"cHZpspuanKwE"},"source":["The appropriate callbacks are set "]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667063552448,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"Wwb8aKhp-Fyn"},"outputs":[],"source":["callbacks_list = [\n","tf.keras.callbacks.ModelCheckpoint(\n","    filepath='/tmp/checkpoint',\n","    save_weights_only=True,\n","    monitor='val_sparse_categorical_accuracy',\n","    mode='max',\n","    save_best_only=True),\n","keras.callbacks.ReduceLROnPlateau(\n","monitor='sparse_categorical_accuracy',\n","factor=0.1,\n","patience=3,\n",")\n","]"]},{"cell_type":"markdown","metadata":{"id":"VAPVqrfdnPR9"},"source":["Finally fitting our model "]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4804443,"status":"error","timestamp":1667068360875,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"la3iD3H6UWjX","outputId":"c44d422a-b3ee-470e-bf7d-8d78dbbe7d4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","199/199 [==============================] - 140s 566ms/step - loss: 4.2216 - sparse_categorical_accuracy: 0.1256 - val_loss: 3.3640 - val_sparse_categorical_accuracy: 0.2659 - lr: 0.0010\n","Epoch 2/100\n","199/199 [==============================] - 94s 473ms/step - loss: 3.4719 - sparse_categorical_accuracy: 0.2297 - val_loss: 2.8680 - val_sparse_categorical_accuracy: 0.3615 - lr: 0.0010\n","Epoch 3/100\n","199/199 [==============================] - 93s 471ms/step - loss: 3.0838 - sparse_categorical_accuracy: 0.2923 - val_loss: 2.3959 - val_sparse_categorical_accuracy: 0.4318 - lr: 0.0010\n","Epoch 4/100\n","199/199 [==============================] - 94s 473ms/step - loss: 2.7894 - sparse_categorical_accuracy: 0.3442 - val_loss: 1.9666 - val_sparse_categorical_accuracy: 0.5035 - lr: 0.0010\n","Epoch 5/100\n","199/199 [==============================] - 91s 459ms/step - loss: 2.5739 - sparse_categorical_accuracy: 0.3796 - val_loss: 1.8828 - val_sparse_categorical_accuracy: 0.5259 - lr: 0.0010\n","Epoch 6/100\n","199/199 [==============================] - 93s 468ms/step - loss: 2.3890 - sparse_categorical_accuracy: 0.4202 - val_loss: 1.7510 - val_sparse_categorical_accuracy: 0.5612 - lr: 0.0010\n","Epoch 7/100\n","199/199 [==============================] - 91s 460ms/step - loss: 2.2364 - sparse_categorical_accuracy: 0.4514 - val_loss: 1.5549 - val_sparse_categorical_accuracy: 0.6145 - lr: 0.0010\n","Epoch 8/100\n","199/199 [==============================] - 90s 455ms/step - loss: 2.0538 - sparse_categorical_accuracy: 0.4879 - val_loss: 1.4815 - val_sparse_categorical_accuracy: 0.6115 - lr: 0.0010\n","Epoch 9/100\n","199/199 [==============================] - 93s 469ms/step - loss: 1.9499 - sparse_categorical_accuracy: 0.5097 - val_loss: 1.3949 - val_sparse_categorical_accuracy: 0.6460 - lr: 0.0010\n","Epoch 10/100\n","199/199 [==============================] - 92s 461ms/step - loss: 1.8381 - sparse_categorical_accuracy: 0.5323 - val_loss: 1.2806 - val_sparse_categorical_accuracy: 0.6635 - lr: 0.0010\n","Epoch 11/100\n","199/199 [==============================] - 91s 459ms/step - loss: 1.7526 - sparse_categorical_accuracy: 0.5557 - val_loss: 1.2347 - val_sparse_categorical_accuracy: 0.6840 - lr: 0.0010\n","Epoch 12/100\n","199/199 [==============================] - 92s 465ms/step - loss: 1.6239 - sparse_categorical_accuracy: 0.5854 - val_loss: 1.1874 - val_sparse_categorical_accuracy: 0.7020 - lr: 0.0010\n","Epoch 13/100\n","199/199 [==============================] - 91s 461ms/step - loss: 1.5546 - sparse_categorical_accuracy: 0.6054 - val_loss: 1.0262 - val_sparse_categorical_accuracy: 0.7384 - lr: 0.0010\n","Epoch 14/100\n","199/199 [==============================] - 90s 456ms/step - loss: 1.4763 - sparse_categorical_accuracy: 0.6254 - val_loss: 1.2257 - val_sparse_categorical_accuracy: 0.7120 - lr: 0.0010\n","Epoch 15/100\n","199/199 [==============================] - 93s 469ms/step - loss: 1.4295 - sparse_categorical_accuracy: 0.6379 - val_loss: 1.0549 - val_sparse_categorical_accuracy: 0.7478 - lr: 0.0010\n","Epoch 16/100\n","199/199 [==============================] - 91s 460ms/step - loss: 1.3631 - sparse_categorical_accuracy: 0.6537 - val_loss: 1.0354 - val_sparse_categorical_accuracy: 0.7592 - lr: 0.0010\n","Epoch 17/100\n","199/199 [==============================] - 92s 462ms/step - loss: 1.3020 - sparse_categorical_accuracy: 0.6709 - val_loss: 0.9567 - val_sparse_categorical_accuracy: 0.7683 - lr: 0.0010\n","Epoch 18/100\n","199/199 [==============================] - 90s 453ms/step - loss: 1.2570 - sparse_categorical_accuracy: 0.6764 - val_loss: 0.9699 - val_sparse_categorical_accuracy: 0.7575 - lr: 0.0010\n","Epoch 19/100\n","199/199 [==============================] - 93s 467ms/step - loss: 1.1929 - sparse_categorical_accuracy: 0.6940 - val_loss: 0.9164 - val_sparse_categorical_accuracy: 0.7837 - lr: 0.0010\n","Epoch 20/100\n","199/199 [==============================] - 93s 467ms/step - loss: 1.1522 - sparse_categorical_accuracy: 0.7005 - val_loss: 0.8708 - val_sparse_categorical_accuracy: 0.7931 - lr: 0.0010\n","Epoch 21/100\n","199/199 [==============================] - 89s 447ms/step - loss: 1.1283 - sparse_categorical_accuracy: 0.7110 - val_loss: 0.9090 - val_sparse_categorical_accuracy: 0.7899 - lr: 0.0010\n","Epoch 22/100\n","199/199 [==============================] - 93s 468ms/step - loss: 1.0855 - sparse_categorical_accuracy: 0.7272 - val_loss: 0.8497 - val_sparse_categorical_accuracy: 0.7996 - lr: 0.0010\n","Epoch 23/100\n","199/199 [==============================] - 92s 463ms/step - loss: 1.0505 - sparse_categorical_accuracy: 0.7319 - val_loss: 0.8795 - val_sparse_categorical_accuracy: 0.8031 - lr: 0.0010\n","Epoch 24/100\n","199/199 [==============================] - 92s 462ms/step - loss: 0.9941 - sparse_categorical_accuracy: 0.7470 - val_loss: 0.8302 - val_sparse_categorical_accuracy: 0.8055 - lr: 0.0010\n","Epoch 25/100\n","199/199 [==============================] - 90s 452ms/step - loss: 0.9792 - sparse_categorical_accuracy: 0.7502 - val_loss: 0.8625 - val_sparse_categorical_accuracy: 0.7996 - lr: 0.0010\n","Epoch 26/100\n","199/199 [==============================] - 92s 461ms/step - loss: 0.9399 - sparse_categorical_accuracy: 0.7622 - val_loss: 0.8479 - val_sparse_categorical_accuracy: 0.7947 - lr: 0.0010\n","Epoch 27/100\n","199/199 [==============================] - 91s 456ms/step - loss: 0.9431 - sparse_categorical_accuracy: 0.7638 - val_loss: 1.2656 - val_sparse_categorical_accuracy: 0.7710 - lr: 0.0010\n","Epoch 28/100\n","199/199 [==============================] - 93s 469ms/step - loss: 0.9362 - sparse_categorical_accuracy: 0.7648 - val_loss: 0.8460 - val_sparse_categorical_accuracy: 0.8101 - lr: 0.0010\n","Epoch 29/100\n","199/199 [==============================] - 89s 449ms/step - loss: 0.9102 - sparse_categorical_accuracy: 0.7681 - val_loss: 0.8768 - val_sparse_categorical_accuracy: 0.8031 - lr: 0.0010\n","Epoch 30/100\n","199/199 [==============================] - 93s 467ms/step - loss: 0.8570 - sparse_categorical_accuracy: 0.7833 - val_loss: 0.8425 - val_sparse_categorical_accuracy: 0.8179 - lr: 0.0010\n","Epoch 31/100\n","199/199 [==============================] - 90s 453ms/step - loss: 0.8336 - sparse_categorical_accuracy: 0.7893 - val_loss: 0.8447 - val_sparse_categorical_accuracy: 0.8090 - lr: 0.0010\n","Epoch 32/100\n","199/199 [==============================] - 91s 459ms/step - loss: 0.8202 - sparse_categorical_accuracy: 0.7918 - val_loss: 0.8170 - val_sparse_categorical_accuracy: 0.8130 - lr: 0.0010\n","Epoch 33/100\n","199/199 [==============================] - 91s 459ms/step - loss: 0.7988 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.8821 - val_sparse_categorical_accuracy: 0.8130 - lr: 0.0010\n","Epoch 34/100\n","199/199 [==============================] - 93s 471ms/step - loss: 0.7900 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.7913 - val_sparse_categorical_accuracy: 0.8305 - lr: 0.0010\n","Epoch 35/100\n","199/199 [==============================] - 90s 452ms/step - loss: 0.7469 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.8089 - val_sparse_categorical_accuracy: 0.8303 - lr: 0.0010\n","Epoch 36/100\n","199/199 [==============================] - 93s 469ms/step - loss: 0.7243 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.8048 - val_sparse_categorical_accuracy: 0.8332 - lr: 0.0010\n","Epoch 37/100\n","199/199 [==============================] - 89s 450ms/step - loss: 0.7381 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.7901 - val_sparse_categorical_accuracy: 0.8262 - lr: 0.0010\n","Epoch 38/100\n","199/199 [==============================] - 91s 457ms/step - loss: 0.7139 - sparse_categorical_accuracy: 0.8141 - val_loss: 0.8371 - val_sparse_categorical_accuracy: 0.8209 - lr: 0.0010\n","Epoch 39/100\n","199/199 [==============================] - 92s 462ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.8261 - val_loss: 0.7711 - val_sparse_categorical_accuracy: 0.8287 - lr: 0.0010\n","Epoch 40/100\n","199/199 [==============================] - 91s 457ms/step - loss: 0.6949 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.8311 - val_sparse_categorical_accuracy: 0.8227 - lr: 0.0010\n","Epoch 41/100\n","199/199 [==============================] - 94s 472ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.8266 - val_sparse_categorical_accuracy: 0.8346 - lr: 0.0010\n","Epoch 42/100\n","199/199 [==============================] - 91s 459ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.8305 - val_loss: 0.7922 - val_sparse_categorical_accuracy: 0.8384 - lr: 0.0010\n","Epoch 43/100\n","199/199 [==============================] - 91s 456ms/step - loss: 0.7471 - sparse_categorical_accuracy: 0.8219 - val_loss: 1.0517 - val_sparse_categorical_accuracy: 0.7961 - lr: 0.0010\n","Epoch 44/100\n","199/199 [==============================] - 91s 460ms/step - loss: 0.6782 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.8333 - val_sparse_categorical_accuracy: 0.8233 - lr: 0.0010\n","Epoch 45/100\n","199/199 [==============================] - 93s 470ms/step - loss: 0.5843 - sparse_categorical_accuracy: 0.8507 - val_loss: 0.7191 - val_sparse_categorical_accuracy: 0.8499 - lr: 1.0000e-04\n","Epoch 46/100\n","199/199 [==============================] - 92s 465ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8571 - val_loss: 0.7107 - val_sparse_categorical_accuracy: 0.8548 - lr: 1.0000e-04\n","Epoch 47/100\n","199/199 [==============================] - 90s 455ms/step - loss: 0.5288 - sparse_categorical_accuracy: 0.8648 - val_loss: 0.7041 - val_sparse_categorical_accuracy: 0.8553 - lr: 1.0000e-04\n","Epoch 48/100\n","199/199 [==============================] - 91s 459ms/step - loss: 0.5041 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.7073 - val_sparse_categorical_accuracy: 0.8583 - lr: 1.0000e-04\n","Epoch 49/100\n","199/199 [==============================] - 91s 459ms/step - loss: 0.5135 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.8594 - lr: 1.0000e-04\n","Epoch 50/100\n","199/199 [==============================] - 90s 453ms/step - loss: 0.5024 - sparse_categorical_accuracy: 0.8724 - val_loss: 0.7198 - val_sparse_categorical_accuracy: 0.8556 - lr: 1.0000e-04\n","Epoch 51/100\n","199/199 [==============================] - 91s 460ms/step - loss: 0.4945 - sparse_categorical_accuracy: 0.8755 - val_loss: 0.7276 - val_sparse_categorical_accuracy: 0.8564 - lr: 1.0000e-04\n","Epoch 52/100\n","198/199 [============================>.] - ETA: 0s - loss: 0.4824 - sparse_categorical_accuracy: 0.8771"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-b8f2e5488c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=validation_dataset,callbacks=callbacks_list)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["historical = model.fit(training_dataset, \n","          steps_per_epoch=STEPS_PER_EPOCH, \n","          epochs=EPOCHS, \n","          validation_data=validation_dataset,callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3822,"status":"ok","timestamp":1667068367953,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"xxy36uEk62Jk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"631e91c7-0335-44de-dc4a-1f7e1ff79b15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94668760/94668760 [==============================] - 1s 0us/step\n"]}],"source":["resnet = ResNet50V2(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3]) \n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667068367953,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"0dX1P9k47OhO"},"outputs":[],"source":["for layer in resnet.layers[:80]:\n","   layer.trainable = False\n","for layer in resnet.layers[81:]:\n","   layer.trainable = True"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667068370945,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"},"user_tz":-330},"id":"PNtBqHr59uXd"},"outputs":[],"source":["model2 = Sequential()\n","model2.add(resnet)\n","model2.add(layers.Flatten())\n","model2.add(Dense(512,activation='relu'))\n","model2.add(layers.Dropout(0.5))\n","model2.add(Dense(256,activation='relu'))\n","model2.add(layers.Dropout(0.5))\n","model2.add(Dense(104,activation='softmax'))\n","model2.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n","    loss = 'sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'])"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"id":"TI3BDOS_-Au0","executionInfo":{"status":"error","timestamp":1667077856398,"user_tz":-330,"elapsed":321875,"user":{"displayName":"Karthik Archit","userId":"11149765067007590192"}},"outputId":"91da4a59-10c4-4773-f01a-c250ee717b5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","199/199 [==============================] - 140s 647ms/step - loss: 0.6590 - sparse_categorical_accuracy: 0.8283 - val_loss: 1.0387 - val_sparse_categorical_accuracy: 0.7869 - lr: 0.0010\n","Epoch 2/100\n","199/199 [==============================] - 129s 648ms/step - loss: 0.6493 - sparse_categorical_accuracy: 0.8316 - val_loss: 1.0810 - val_sparse_categorical_accuracy: 0.7901 - lr: 0.0010\n","Epoch 3/100\n"," 88/199 [============>.................] - ETA: 1:05 - loss: 0.6379 - sparse_categorical_accuracy: 0.8350"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-ac1d688c2e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=validation_dataset)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model2_history = model2.fit(training_dataset, \n","          steps_per_epoch=STEPS_PER_EPOCH, \n","          epochs=EPOCHS,callbacks=callbacks_list, \n","          validation_data=validation_dataset)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"mount_file_id":"1RUqftcYvPZG8ryua9RYTPRSgGF8inv05","authorship_tag":"ABX9TyO0lru+4GHeME7fLoHCbGGl"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}